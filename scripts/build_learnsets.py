"""
Handles generating learnset codetables which are packed into NARC subfiles in codetables.mk

Responsible for:
  data/TMLearnsets.c
  data/LevelupLearnsets.c
  data/EggLearnsets.c
"""

import re
import json
import argparse

# TODO zebben
MAX_NUM_TMHMS = 128
TM_LEARNSETS_BITS_PER_WORD = 32
TM_LEARNSETS_BITFIELD_COUNT = MAX_NUM_TMHMS // TM_LEARNSETS_BITS_PER_WORD
MAX_NUM_LEVELUP_MOVES = 40
MAX_EGG_MOVES = 16
MOVESET_TERMINATOR_32BIT = 0x0000FFFF
MOVESET_TERMINATOR_16BIT = 0xFFFF


def load_species_header(file_path):
    species_dict = {}
    index = 0
    with open(file_path) as f:
        for line in f:
            if len(line.split()) > 1:
                test = line.split()[1].strip()
                if 'SPECIES' in test and not '_START' in test and not '_SPECIES_H' in test and not '_NUM (' in line and not 'MAX_' in test:
                    species_dict[test] = index
                    index += 1
    return species_dict


def load_moves_header(file_path):
    moves_dict = {}
    index = 0
    with open(file_path) as f:
        for line in f:
            if len(line.split()) > 1:
                test = line.split()[1].strip()
                if 'MOVE' in test and not '_START' in test and not '_MOVES_H' in test and not 'NUM_OF' in test:
                    moves_dict[test] = index
                    index += 1
    return moves_dict


def load_tmhm_list(file_path):
    move_list = []
    in_array = False
    move_pattern = re.compile(r'\bMOVE_[A-Z0-9_]+')

    with open(file_path, encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if 'static const u16 sTMHMMoves[]' in line:
                in_array = True
                continue
            if in_array:
                if '};' in line:
                    break
                matches = move_pattern.findall(line)
                move_list.extend(matches)

    return move_list


def write_tm_data(species_dict, moves_dict, species_learnsets, tmhm_moves, output_path):
    tm_move_to_index = {
        move_name: idx
        for idx, move_name in enumerate(tmhm_moves)
        if move_name in moves_dict
    }

    max_species_index = max(species_dict.values())
    species_id_to_name = {v: k for k, v in species_dict.items()}

    with open(output_path, "w") as out:
        out.write("// DO NOT MODIFY THIS FILE!  autogenerated by build_learnsets.py\n\n")
        out.write("#include \"../include/types.h\"\n")
        out.write("#include \"../include/config.h\"\n")
        out.write("#include \"../include/constants/species.h\"\n")
        out.write("#include \"../include/constants/item.h\"\n\n")
        out.write(f"const u32 UNUSED TMLearnsets[][TM_LEARNSETS_BITFIELD_COUNT] = {{\n")

        for species_id in range(max_species_index + 1):
            species_name = species_id_to_name.get(species_id)
            learnset = []
            if species_name:
                learnset = species_learnsets.get(species_name, {}).get("TMMoves", [])
                learnset = list(set(m.strip() for m in learnset))

            parts = [0] * TM_LEARNSETS_BITFIELD_COUNT
            for move in learnset:
                tm_index = tm_move_to_index.get(move)
                if tm_index is not None and tm_index < MAX_NUM_TMHMS:
                    word = tm_index // TM_LEARNSETS_BITS_PER_WORD
                    bit = tm_index % TM_LEARNSETS_BITS_PER_WORD
                    parts[word] |= (1 << bit)

            formatted = ", ".join(f"0x{val:08X}" for val in parts)
            out.write(f"    [{species_name}] = {{ {formatted} }},\n")

        out.write("};\n")


def write_levelup_data(species_dict, moves_dict, species_learnsets, output_path):
    species_id_to_name = {v: k for k, v in species_dict.items()}
    max_species_id = max(species_id_to_name.keys())
    col_len = 8

    with open(output_path, "w") as out:
        out.write("// DO NOT MODIFY THIS FILE! Autogenerated by build_learnsets.py\n\n")
        out.write("#include \"../include/types.h\"\n")
        out.write("#include \"../include/config.h\"\n")
        out.write("#include \"../include/constants/species.h\"\n\n")
        out.write("const u32 UNUSED LevelUpLearnsets[][MAX_LEVELUP_MOVES] = {\n")

        for species_id in range(max_species_id + 1):
            species_name = species_id_to_name.get(species_id)
            learnset = []
            if species_name:
                learnset = species_learnsets.get(species_name, {}).get("LevelMoves", [])

            entries = []

            for move_entry in learnset:
                move = move_entry.get("Move", "").strip()
                level = int(move_entry["Level"])
                if not move or move not in moves_dict:
                    print(f"[ERROR]: Invalid or missing move '{move}' for species '{species_name}' at level {level}")
                    exit(1)

                move_id = moves_dict[move]
                encoded = (level << 16) | move_id
                entries.append(encoded)

            entries.append(MOVESET_TERMINATOR_32BIT)
            while len(entries) < MAX_NUM_LEVELUP_MOVES:
                entries.append(MOVESET_TERMINATOR_32BIT)

            out.write(f"    [{species_name}] = {{\n")
            for i in range(0, MAX_NUM_LEVELUP_MOVES, col_len):
                line = ", ".join(f"0x{val:08X}" for val in entries[i:i+col_len])
                out.write(f"        {line},\n")
            out.write("    },\n")

        out.write("};\n")


def write_eggmove_data(species_dict, moves_dict, species_learnsets, output_path):
    species_id_to_name = {v: k for k, v in species_dict.items()}
    max_species_id = max(species_id_to_name)
    col_len = 12

    with open(output_path, "w") as out:
        out.write("// DO NOT MODIFY THIS FILE! Autogenerated by build_learnsets.py\n\n")
        out.write("#include \"../include/types.h\"\n")
        out.write("#include \"../include/config.h\"\n")
        out.write("#include \"../include/constants/species.h\"\n\n")
        out.write("const u16 UNUSED EggMoves[][MAX_EGG_MOVES] = {\n")

        for species_id in range(max_species_id + 1):
            species_name = species_id_to_name.get(species_id, "")
            egg_moves = []

            if species_name:
                egg_moves = species_learnsets.get(species_name, {}).get("EggMoves", [])

            moves = []
            for move in egg_moves:
                if move not in moves_dict:
                    print(f"[ERROR]: Move '{move}' not found in moves.h")
                    exit(1)
                moves.append(moves_dict[move])

            # Add terminator and pad to fixed length
            moves.append(0xFFFF)
            while len(moves) < MAX_EGG_MOVES:
                moves.append(0xFFFF)

            out.write(f"    [{species_name}] = {{\n")
            for i in range(0, MAX_EGG_MOVES, col_len):
                chunk = moves[i:i+col_len]
                out.write("        " + ", ".join(f"0x{m:04X}" for m in chunk) + ",\n")
            out.write("    },\n")

        out.write("};\n")


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--learnsets", default="data/mon/learnsets.json")

    parser.add_argument("--tmout")

    parser.add_argument("--levelupout")

    parser.add_argument("--eggout")

    args = parser.parse_args()

    tmhm_moves = load_tmhm_list("src/item.c")
    species_dict = load_species_header("include/constants/species.h")
    moves_dict = load_moves_header("include/constants/moves.h")

    with open(args.learnsets, encoding="utf-8") as f:
        species_learnsets = json.load(f)

    if args.tmout:
        write_tm_data(species_dict, moves_dict, species_learnsets, tmhm_moves, args.tmout)

    if args.levelupout:
        write_levelup_data(species_dict, moves_dict, species_learnsets, args.levelupout)

    if args.eggout:
        write_eggmove_data(species_dict, moves_dict, species_learnsets, args.eggout)
